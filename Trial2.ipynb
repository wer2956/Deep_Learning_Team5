{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "#np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('./data_origin/train/')\n",
    "test_dir = os.path.join('./data_origin/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dyed-lifted-polyps', 'dyed-resection-margins', 'esophagitis', 'normal-cecum', 'normal-pylorus', 'normal-z-line', 'polyps', 'ulcerative-colitis']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "imsidir = os.path.join('./data_origin/train/')\n",
    "folder_list = os.listdir(imsidir)\n",
    "print(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "folder_list = os.listdir(test_dir)\n",
    "for foldername in folder_list:\n",
    "    imsidir = os.path.join(test_dir, foldername)\n",
    "    image_list = os.listdir(imsidir)\n",
    "    for filename in image_list:\n",
    "        imagename = os.path.join(imsidir,filename)\n",
    "        img = Image.open(imagename)\n",
    "        width , height = img.size\n",
    "        if width == 1920:\n",
    "            area = (340,0,width, height)\n",
    "            cropped_img = img.crop(area)\n",
    "            cropped_img.save(imagename);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7200 images belonging to 8 classes.\n",
      "Found 800 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255)      # 영상의 전체 픽셀을 255로 나눈다 - 영상이 0~1사이의 범위를 가지게 된다(normalization)\n",
    "#      rotation_range=40,\n",
    " #     width_shift_range=0.2,\n",
    "  #    height_shift_range=0.2,\n",
    "   #   shear_range=0.2,\n",
    "    #  zoom_range=0.2,\n",
    "     # horizontal_flip=True,\n",
    "      #fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(90,72),\n",
    "                                                   batch_size=100,\n",
    "                                                   class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                 target_size=(90,72),\n",
    "                                                 batch_size=10,\n",
    "                                                 class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 데이터 크기: (100, 90, 72, 3)\n",
      "배치 레이블 크기: (100, 8)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('배치 데이터 크기:', data_batch.shape)\n",
    "    print('배치 레이블 크기:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dahyun\\Anaconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dahyun\\Anaconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dahyun\\Anaconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dahyun\\Anaconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                activation='relu',\n",
    "                input_shape=(90,72,3)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 88, 70, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 86, 68, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 43, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 93568)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               11976832  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 11,997,256\n",
      "Trainable params: 11,997,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dahyun\\Anaconda3\\envs\\test\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dahyun\\Anaconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dahyun\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\dahyun\\Anaconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 52s 3s/step - loss: 2.7301 - acc: 0.3490 - val_loss: 1.0986 - val_acc: 0.5220\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 33s 2s/step - loss: 0.9247 - acc: 0.5620 - val_loss: 0.7943 - val_acc: 0.6320\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.7844 - acc: 0.6290 - val_loss: 0.6981 - val_acc: 0.6900\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.7311 - acc: 0.6830 - val_loss: 0.6961 - val_acc: 0.6890\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.6523 - acc: 0.7045 - val_loss: 0.6401 - val_acc: 0.7180\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.6103 - acc: 0.7250 - val_loss: 0.5679 - val_acc: 0.7350\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 31s 2s/step - loss: 0.5868 - acc: 0.7530 - val_loss: 0.5666 - val_acc: 0.7600\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 31s 2s/step - loss: 0.5421 - acc: 0.7610 - val_loss: 0.6145 - val_acc: 0.7180\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.5482 - acc: 0.7635 - val_loss: 0.5680 - val_acc: 0.7410\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.5107 - acc: 0.7730 - val_loss: 0.5285 - val_acc: 0.7660\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(train_generator,\n",
    "                           steps_per_epoch=20,\n",
    "                           epochs=10,\n",
    "                           validation_data=test_generator,\n",
    "                           validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6474133551120758, 0.690000006556511]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator, steps=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
