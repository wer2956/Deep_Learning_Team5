{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (truncated file: eof = 8388608, sblock->base_addr = 0, stored_eof = 88852744)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dfae8a71f4ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'kvasir_v2.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 8388608, sblock->base_addr = 0, stored_eof = 88852744)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model # 저장된 모델을 로드하기 위함\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = load_model('kvasir_v2.h5')\n",
    "print(model.summary())\n",
    "\n",
    "img_path = 'e0fe569d-cc8d-4871-88d0-5477f4aa6e66.jpg'\n",
    "img = image.load_img(img_path, target_size=(128, 128))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a2078290c1af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m layer_outputs = [layer.output # for loop을 통해서 총 8개의 output이 들어가게 된다\n\u001b[1;32m----> 5\u001b[1;33m                  for layer in model.layers[:8]]\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m activation_model = models.Model(inputs = model.input,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#특정 입력영상에 대한 각 레이어의 Activation Map 출력\n",
    "from keras import models\n",
    "\n",
    "layer_outputs = [layer.output # for loop을 통해서 총 8개의 output이 들어가게 된다\n",
    "                 for layer in model.layers[:8]]\n",
    "\n",
    "activation_model = models.Model(inputs = model.input,\n",
    "                                outputs = layer_outputs)\n",
    "\n",
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "layer_names = []              # 층의 이름을 그래프 제목으로 사용, 모델에 있는 layer의 이름을 가져온다\n",
    "for layer in model.layers[:8]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 프로젝트 시 이 셀과 밑의 셀 반드시 포함하여 filter에 관한 내용을 분석하여야 한다\n",
    "# feature map\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations): # zip:두 인자들을 하나의 짝으로 묶어준다/연결시켜준다\n",
    "\n",
    "    n_features = layer_activation.shape[-1] # layer의 feature의 개수를 추출하여 n_features에 저장\n",
    "    size = layer_activation.shape[1]        # 영상의 x,y사이즈가 동일해서 그 중 하나를 가져온 것\n",
    "\n",
    "\n",
    "    n_cols = n_features // images_per_row\n",
    "    # images_per_row = 20이므로 나눈 몫이 열의 개수가 된다\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    # 영상의 픽셀 사이즈를 정함. 앞: 가로축 길이 / 뒤: 세로축의 길이\n",
    "    # 즉, 전체 디스플레이할 크기를 의미한다\n",
    "\n",
    "\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, col * images_per_row + row] # for loop으로 하나씩 feature를 추출하는\n",
    "            \n",
    "            # 영상의 intensity를 조정하는 과정 (Normalize하는 과정)\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64  # 전체 영상의 variation을 일정하게 잡아주도록 64를 곱해준다. 일종의 histogram equalization과 비슷\n",
    "            channel_image += 128 # 영상의 평균값이 128이 되도록 만들어 준다\n",
    "            \n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, # 처리된 영상을 각 그리드에 뿌려준다\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n",
    "plt.show() # 하나의 layer가 완성되면 for loop이 멈추고 plt.show()로 출력된다. 즉, layer하나하나씩 출력된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 레이어의 필터 특성 출력\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras import backend as K\n",
    "\n",
    "model = VGG16(weights='imagenet',\n",
    "              include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # 1번째 함수\n",
    "def deprocess_image(x):\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1     # standard deviation의 분포를 조정한다. mean과 표준편차를 변화시켜준다\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "    # 즉, 데이터의 분포를 내가 원하는대로 조정하는 과정이다\n",
    "\n",
    "    x *= 255 # 표준편차를 255로 맞춰줌\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "  \n",
    "# 2번째 함수\n",
    "# 영상의 필터를 잡아주는 역할  \n",
    "def generate_pattern(layer_name, filter_index, size=128):\n",
    "    layer_output = model.get_layer(layer_name).output  # get_layer: 해당 모델의 layer를 가져온다\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index]) # 가져온 layer에 해당하는 출력을 지정한다\n",
    "\n",
    "    grads = K.gradients(loss, model.input)[0]          # modle.input에 대한 loss의 gradient를 출력해준다. 즉, gradient를 가져오는 과정이다\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)  # 전체의 gradient값으로 normalize 해주는 과정\n",
    "    iterate = K.function([model.input], [loss, grads]) # loss와 gradient를 출력해주는 함수 생성\n",
    "    \n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "    # 128을 기준으로 랜덤값을 집어넣는다(0에서 1사이 float를 출력). 여기서는 거기다가 20을 곱해줌\n",
    "    # 128(회색). 랜덤영상을 만들어주는 과정\n",
    "\n",
    "    step = 1.\n",
    "    for i in range(40):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)\n",
    "  \n",
    "for layer_name in ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1']: # VCG16에 있는 레이어의 이름들\n",
    "    size = 64       # 영상 사이즈\n",
    "    margin = 5\n",
    "\n",
    "    results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3), dtype='uint8')\n",
    "\n",
    "    for i in range(8):   # filter의 개수를 지정해줌 --> 총 64개\n",
    "        for j in range(8): \n",
    "\n",
    "            filter_img = generate_pattern(layer_name, i + (j * 8), size=size) # layer name으로부터 각 layer의 pattern을 가져온다\n",
    "            # 각 filter의 특징을 영상으로 저장하는 것이다\n",
    "\n",
    "            horizontal_start = i * size + i * margin\n",
    "            horizontal_end = horizontal_start + size\n",
    "            vertical_start = j * size + j * margin\n",
    "            vertical_end = vertical_start + size\n",
    "            results[horizontal_start: horizontal_end, vertical_start: vertical_end, :] = filter_img\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기부터 매우매우 중요함!\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "K.clear_session()\n",
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'e0fe569d-cc8d-4871-88d0-5477f4aa6e66.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0]) # 제일 처음 3개를 가져와서 출력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기부터 셀 매우 중요 --> 응용해서 쓸 수 있어야 한다\n",
    "\n",
    "predict_output = model.output[:, np.argmax(preds[0])]\n",
    "\n",
    "last_conv_layer = model.get_layer('block5_conv3') # 마지막 층\n",
    "grads = K.gradients(predict_output, last_conv_layer.output)[0] \n",
    "\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2)) # 전체의 average가 가장 높은 gradient를 갖는 필터 하나를 선택한다\n",
    "\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]]) # 마지막 레이어를 가져온다\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(512):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i] # 출력 중 가장 gradient가 높은 것들을 곱한다\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1) # 마지막 axis가 feature에 해당되는 axis\n",
    "    \n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap) # heatmap\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(img) # 원본 영상\n",
    "plt.show()\n",
    "# heatmap: convolution layer에서 가장 값이 높은 것을 표시한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "background=image.img_to_array(img)\n",
    "heatmap = cv2.resize(heatmap, (background.shape[1], background.shape[0])) # 영상 사이즈를 키운다\n",
    "heatmap = np.uint8(255 * heatmap)                      # 전체 범위를 255로 키운다\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) # 컬러맵을 바꿔줌\n",
    "\n",
    "superimposed_img =  np.uint8(heatmap * 0.4+ background*0.6) # 영상 mixing. 두 비율의 합이 1이 되도록 설정해주면 된다 (0.4 + 0.6 = 1)\n",
    "plt.matshow(superimposed_img)\n",
    "plt.show()\n",
    "\n",
    "cv2.imwrite('res_img.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
