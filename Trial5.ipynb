{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: './Desktop/data_origin/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-be26dd03d2c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimsidir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Desktop/data_origin/train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfolder_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimsidir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolder_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfolder_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './Desktop/data_origin/train'"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join('./Desktop/data_origin/train')\n",
    "test_dir = os.path.join('./Desktop/data_origin/test')\n",
    "\n",
    "imsidir = os.path.join('./Desktop/data_origin/train')\n",
    "folder_list = os.listdir(imsidir)\n",
    "categories = folder_list\n",
    "folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = os.listdir(train_dir)\n",
    "for foldername in folder_list:\n",
    "    imsidir = os.path.join(train_dir, foldername)\n",
    "    image_list = os.listdir(imsidir)\n",
    "    for filename in image_list:\n",
    "        imagename = os.path.join(imsidir,filename)\n",
    "        img = Image.open(imagename)\n",
    "        width, height = img.size\n",
    "        # square matrix가 되도록 통일 (shape은 512 x 512)\n",
    "        if width == 720:\n",
    "            area = (149, 32, 661, 544)\n",
    "            cropped_img = img.crop(area)\n",
    "            cropped_img.save(imagename)\n",
    "        if width == 1920:\n",
    "            w, h = img.size\n",
    "            w = int(w/2)\n",
    "            h = int(h/2)\n",
    "            img_r = img.resize((w,h), resample=0, box=None)\n",
    "            area = (309, 12, 821, 524)\n",
    "            cropped_img = img_r.crop(area)\n",
    "            cropped_img.save(imagename)\n",
    "        if width == 1280:\n",
    "            w, h = img.size\n",
    "            w = int(w/2)\n",
    "            h = int(h/2)\n",
    "            img_r = img.resize((w,h), resample=0, box=None)\n",
    "            area = (64, 0, 576, 512)\n",
    "            cropped_img = img_r.crop(area)\n",
    "            cropped_img.save(imagename)\n",
    "        if width == 1350:\n",
    "            if height == 1080:\n",
    "                w, h = img.size\n",
    "                w = int(w/2)\n",
    "                h = int(h/2)\n",
    "                img_r = img.resize((w,h), resample=0, box=None)\n",
    "                area = (81, 14, 593, 526)\n",
    "                cropped_img = img_r.crop(area)\n",
    "                cropped_img.save(imagename)\n",
    "            else:\n",
    "                w, h = img.size\n",
    "                w = int(w/2)\n",
    "                h = int(h/2)\n",
    "                img_r = img.resize((w,h), resample=0, box=None)\n",
    "                area = (81, 10, 593, 522)\n",
    "                cropped_img = img_r.crop(area)\n",
    "                cropped_img.save(imagename)                \n",
    "        if width == 576:\n",
    "            w, h = img.size\n",
    "            img_r = img.resize((w,h), resample=0, box=None)\n",
    "            area = (39, 39, 551, 551)\n",
    "            cropped_img = img_r.crop(area)\n",
    "            cropped_img.save(imagename)\n",
    "        \n",
    "        print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = os.listdir(test_dir)\n",
    "for foldername in folder_list:\n",
    "    imsidir = os.path.join(test_dir, foldername)\n",
    "    image_list = os.listdir(imsidir)\n",
    "    for filename in image_list:\n",
    "        imagename = os.path.join(imsidir,filename)\n",
    "        img = Image.open(imagename)\n",
    "        width, height = img.size\n",
    "        # square matrix가 되도록 통일 (shape은 512 x 512)\n",
    "        if width == 720:\n",
    "            area = (149, 32, 661, 544)\n",
    "            cropped_img = img.crop(area)\n",
    "            cropped_img.save(imagename)\n",
    "        if width == 1920:\n",
    "            w, h = img.size\n",
    "            w = int(w/2)\n",
    "            h = int(h/2)\n",
    "            img_r = img.resize((w,h), resample=0, box=None)\n",
    "            area = (309, 12, 821, 524)\n",
    "            cropped_img = img_r.crop(area)\n",
    "            cropped_img.save(imagename)\n",
    "        if width == 1280:\n",
    "            w, h = img.size\n",
    "            w = int(w/2)\n",
    "            h = int(h/2)\n",
    "            img_r = img.resize((w,h), resample=0, box=None)\n",
    "            area = (64, 0, 576, 512)\n",
    "            cropped_img = img_r.crop(area)\n",
    "            cropped_img.save(imagename)\n",
    "        if width == 1350:\n",
    "            if height == 1080:\n",
    "                w, h = img.size\n",
    "                w = int(w/2)\n",
    "                h = int(h/2)\n",
    "                img_r = img.resize((w,h), resample=0, box=None)\n",
    "                area = (81, 14, 593, 526)\n",
    "                cropped_img = img_r.crop(area)\n",
    "                cropped_img.save(imagename)\n",
    "            else:\n",
    "                w, h = img.size\n",
    "                w = int(w/2)\n",
    "                h = int(h/2)\n",
    "                img_r = img.resize((w,h), resample=0, box=None)\n",
    "                area = (81, 10, 593, 522)\n",
    "                cropped_img = img_r.crop(area)\n",
    "                cropped_img.save(imagename)        \n",
    "        if width == 576:\n",
    "            w, h = img.size\n",
    "            img_r = img.resize((w,h), resample=0, box=None)\n",
    "            area = (39, 39, 551, 551)\n",
    "            cropped_img = img_r.crop(area)\n",
    "            cropped_img.save(imagename)\n",
    "        \n",
    "        print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(128,128),\n",
    "                                                   batch_size=720,\n",
    "                                                   class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                 target_size=(128,128),\n",
    "                                                 batch_size=1,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('배치 데이터 크기:', data_batch.shape)\n",
    "    print('배치 레이블 크기:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=20,\n",
    "                              epochs=10,\n",
    "                              validation_data=test_generator,\n",
    "                              validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('kvasir_v2.h5')\n",
    "#model = load_model('kvasir_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, steps=800)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = list(np.arange(8))\n",
    "class_label = {}\n",
    "\n",
    "for i in range(8):\n",
    "    class_label[class_idx[i]] = categories[i]\n",
    "\n",
    "y_predict = model.predict_generator(test_generator, steps=800)\n",
    "predicted_class = np.argmax(y_predict, axis=1)\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [class_idx[k] for k in predicted_class]\n",
    "predictions2 = [class_label[k] for k in predicted_class]\n",
    "\n",
    "def pred_class(i):\n",
    "    print(i, '번째를 예측한 내시경 영상 : ', predictions[i], predictions2[i])\n",
    "pred_class(798)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(j):\n",
    "    print(test_generator[j][1]) # 답\n",
    "    pred_class(j) # 모델이 예측한 답\n",
    "check(798)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
